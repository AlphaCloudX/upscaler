# upscaler

training data:
url = "http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz"

peaks at 29gb of ram usage

trained for x2 upscaling 720p to 2k
 -2560x1440 <--> 1280x720

Progress:
Mon-Tues: researching what archecture to use, settled on cnn approach because have most experience
planning on doing lstm or gan but too complex

wednesday: found source to work off of, source was broken/not functional so found another that was slightly different with its implementation

thursday reverse engineering the source and seeing the work flow of the project, testing around how everything works

friday and weekend and monday was coding from scratch with custom model(using modified mobilenetv2 architecture to benefit from faster upscale times)
has shown to be effective but problem with accuracy

plans are to improve model, add more augmentations such as blur, jpg compression, noise, etc. <--tensorflow can't do these by batches
curently only using random vertical flip on data

improve speed, try to load model in c++, java or c-python
try to upscale low res image using regular upscaling algorithm and then working from there reducing time the ai has to compute

higher the psnr the better
also check against ssim for structural similarity index


nvidia does x4 upscaling with 1.5ms / 0.015s to upscale from 1080p to 4k
-------------------------------------------------------------------------------------------
DLSS 2.0 has two primary inputs into the AI network:

Low resolution, aliased images rendered by the game engine
Low resolution, motion vectors from the same images -- also generated by the game engine

Motion vectors tell us which direction objects in the scene are moving from frame to frame. We can apply these vectors to the previous high resolution output to estimate what the next frame will look like. We refer to this process as ‘temporal feedback,’ as it uses history to inform the future.

A special type of AI network, called a convolutional autoencoder, takes the low resolution current frame, and the high resolution previous frame, to determine on a pixel-by-pixel basis how to generate a higher quality current frame


